"""Async agent implementation using direct Anthropic API."""

import json
from collections.abc import AsyncIterator
from pathlib import Path
from typing import Any

from anthropic import AsyncAnthropic, AsyncMessageStream, MessageStreamEvent
from anthropic.types import TextBlock, TextDelta, ThinkingBlock, ThinkingDelta, ToolUseBlock
from anthropic.types.input_json_delta import InputJsonDelta
from dotenv import load_dotenv

from .config import AgentConfig
from .console_handler import ConsoleStreamHandler
from .entities import (
    ContentDeltaType,
    ContentType,
    Event,
    EventType,
    Role,
    StopReason,
    TextContent,
    ThinkingContent,
    ToolResultContent,
    ToolUseContent,
    Usage,
)
from .file_system_agent import FileSystemAgent
from .stream_processor import CompleteResponse, StreamProcessor
from .tools_registry import ToolsRegistry


class ChunkType(str):
    """Message chunk types"""

    MessageStart = "message_start"
    MessageDelta = "message_delta"
    MessageStop = "message_stop"
    ContentBlockStart = "content_block_start"
    ContentBlockDelta = "content_block_delta"
    ContentBlockStop = "content_block_stop"


class AsyncAgentRuntime:
    """Async agent runtime using direct Anthropic API"""

    def __init__(self, project_root: Path, config: AgentConfig | None = None):
        self.project_root = Path(project_root)
        self.agent = FileSystemAgent("main", "context_window_main.md", project_root)

        # Load environment variables
        load_dotenv()

        # Initialize configuration
        self.config = config or AgentConfig.from_env()
        if not self.config.api_key:
            raise ValueError("ANTHROPIC_API_KEY not found in environment variables")

        # Create Anthropic client
        self._client: AsyncAnthropic | None = None

        # Message history for the current conversation
        self.messages: list[Event] = []

        # Usage tracking
        self.total_usage = Usage()

    @property
    def client(self) -> AsyncAnthropic:
        """Get or create Anthropic client"""
        if self._client is None:
            self._client = AsyncAnthropic(
                api_key=self.config.api_key, base_url=self.config.base_url
            )
        return self._client

    def _format_tools(self) -> list[dict[str, Any]]:
        """Convert tools to Claude API format"""
        # ä»ç»Ÿä¸€çš„å·¥å…·æ³¨å†Œä¸­å¿ƒè·å–å·¥å…·å®šä¹‰
        return ToolsRegistry.get_all_tools()

    def _build_request_params(self) -> dict[str, Any]:
        """Build request parameters"""
        params = self.config.get_request_params()
        params["tools"] = self._format_tools()
        return params

    async def _load_system_context(self) -> str:
        """Load guideline and context window"""
        # This is synchronous for now, matching the original implementation
        guideline_path = self.agent.path_manager.agent_root / "guideline.md"
        context_path = self.agent.path_manager.agent_root / self.agent.context_file

        guideline = guideline_path.read_text(encoding="utf-8") if guideline_path.exists() else ""
        context = context_path.read_text(encoding="utf-8") if context_path.exists() else ""

        # è‡ªåŠ¨ç”Ÿæˆæ–‡ä»¶ç³»ç»Ÿç»“æ„
        structure = self._generate_directory_structure()

        return self._build_system_prompt(guideline, context, structure)

    def _build_system_prompt(self, guideline: str, context: str, structure: str) -> str:
        """Build system prompt from components"""
        system_prompt = f"""# ä½ çš„è¡Œä¸ºå‡†åˆ™
{guideline}

# ä½ çš„å½“å‰è®°å¿†
{context}

# ä½ çš„æ–‡ä»¶ç³»ç»Ÿç»“æ„
{structure}

# å·¥å…·ä½¿ç”¨è¯´æ˜
ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·ï¼š
1. shell - æ‰§è¡Œå‘½ä»¤è¡Œå·¥å…·ï¼ˆä¼˜å…ˆä½¿ç”¨ï¼‰
   - æ”¯æŒ ls, cat, grep, sed, awk, python, git, curl ç­‰
   - Shell ä¼šè¯ä¿æŒçŠ¶æ€ï¼Œcd ä¼šæ”¹å˜ç›®å½•
2. edit_file - ç¼–è¾‘æ–‡ä»¶çš„ç‰¹å®šè¡Œï¼ˆç”¨äºå¤§æ–‡ä»¶ï¼‰
3. create_file - åˆ›å»ºåŒ…å«å¤§é‡å†…å®¹çš„æ–°æ–‡ä»¶
4. sync_context - æ›´æ–°ä½ çš„å·¥ä½œè®°å¿†

# é‡è¦æé†’
1. ä¼˜å…ˆä½¿ç”¨ shell å‘½ä»¤è§£å†³é—®é¢˜
2. æ‰€æœ‰è·¯å¾„éƒ½æ˜¯çœŸå®è·¯å¾„ï¼Œç›¸å¯¹äº {self.agent.path_manager.agent_root}
3. è°ƒç”¨ sync_context æ—¶éœ€è¦æä¾›å®Œæ•´çš„æ–° context å†…å®¹
4. æ¯ 3-5 ä¸ªæ“ä½œååŒæ­¥ä¸€æ¬¡ï¼Œä¿æŒ context ç²¾ç®€è€Œå®Œæ•´

å½“éœ€è¦ä½¿ç”¨å·¥å…·æ—¶ï¼Œè¯·ç›´æ¥è°ƒç”¨ç›¸åº”çš„å·¥å…·ã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨å’Œç»“æœè¿”å›ã€‚
"""
        return system_prompt

    def _generate_directory_structure(self, max_depth: int = 10) -> str:
        """ç”Ÿæˆå®Œæ•´çš„ç›®å½•æ ‘ç»“æ„"""
        lines = ["```"]
        lines.append("/")

        def walk_directory(path, prefix="", depth=0, is_last_parent=True):
            if depth >= max_depth:
                return

            try:
                # è·å–å¹¶æ’åºç›®å½•å†…å®¹ï¼šå…ˆç›®å½•åæ–‡ä»¶
                items = sorted(path.iterdir(), key=lambda x: (not x.is_dir(), x.name.lower()))

                for i, item in enumerate(items):
                    is_last = i == len(items) - 1

                    # ç¡®å®šå‰ç¼€
                    if depth == 0:
                        current_prefix = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                        next_prefix = "    " if is_last else "â”‚   "
                    else:
                        current_prefix = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                        next_prefix = prefix + ("    " if is_last else "â”‚   ")

                    # è·³è¿‡ä¸€äº›ç³»ç»Ÿæ–‡ä»¶
                    if item.name in [".DS_Store", "__pycache__", ".git", ".gitkeep"]:
                        continue

                    if item.is_dir():
                        # ç›®å½•æ˜¾ç¤º
                        lines.append(f"{prefix}{current_prefix}{item.name}/")
                        # é€’å½’å¤„ç†å­ç›®å½•
                        walk_directory(item, next_prefix, depth + 1, is_last)
                    else:
                        # æ–‡ä»¶æ˜¾ç¤ºï¼ŒåŒ…å«å¤§å°ä¿¡æ¯
                        try:
                            size = item.stat().st_size
                            if size < 1024:
                                size_str = f" ({size}B)"
                            elif size < 1024 * 1024:
                                size_str = f" ({size / 1024:.1f}KB)"
                            else:
                                size_str = f" ({size / 1024 / 1024:.1f}MB)"
                        except Exception:
                            size_str = ""

                        lines.append(f"{prefix}{current_prefix}{item.name}{size_str}")

            except Exception as e:
                lines.append(f"{prefix}[Error: {e}]")

        # ä» agent_root å¼€å§‹éå†
        walk_directory(self.agent.path_manager.agent_root)
        lines.append("```")

        return "\n".join(lines)

    async def invoke(self, role: str = "user", content: str = "", max_rounds: int = 10) -> CompleteResponse:
        """
        éæµå¼æ¥å£ï¼Œè¿”å›å®Œæ•´å“åº”ï¼Œæ”¯æŒå¤šè½®å·¥å…·è°ƒç”¨

        Args:
            role: æ¶ˆæ¯è§’è‰²
            content: æ¶ˆæ¯å†…å®¹
            max_rounds: æœ€å¤§è½®æ•°ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰

        Returns:
            CompleteResponse: åŒ…å«å®Œæ•´æ–‡æœ¬ã€å·¥å…·è°ƒç”¨ã€ä½¿ç”¨æƒ…å†µç­‰
        """
        # åªåœ¨æœ‰å†…å®¹æ—¶æ·»åŠ åˆå§‹ç”¨æˆ·æ¶ˆæ¯ï¼ˆç¬¬ä¸€è½®ï¼‰
        if role and content:
            await self.create_event(Role(role), EventType.Message, TextContent(text=content))

        # ç´¯ç§¯çš„å®Œæ•´å“åº”
        final_response = CompleteResponse(
            text="",
            tool_calls=[],
            stop_reason=None,
            usage=None,
            thinking=None,
            tool_results=[]
        )

        # å¾ªç¯å¤„ç†ï¼Œæœ€å¤š max_rounds è½®
        for round_num in range(max_rounds):  # noqa: B007
            # åŠ è½½ç³»ç»Ÿä¸Šä¸‹æ–‡
            system_prompt = await self._load_system_context()
            self.config.system_prompt = system_prompt

            # å‡†å¤‡ API æ¶ˆæ¯
            api_messages = [msg.transform_api() for msg in self.messages]

            # åˆ›å»ºæµ
            stream_params = {
                "model": self.config.model,
                "messages": api_messages,
                **self._build_request_params(),
                "timeout": self.config.timeout,
            }

            # æ·»åŠ  beta ç‰¹æ€§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.config.beta and self.config.betas():
                stream_call = self.client.beta.messages.stream
                stream_params["betas"] = self.config.betas()
            else:
                stream_call = self.client.messages.stream

            # ä½¿ç”¨ StreamProcessor å¤„ç†æµ
            processor = StreamProcessor()

            async with stream_call(**stream_params) as stream:
                response = await processor.process_stream(stream)

            # ç´¯ç§¯å“åº”å†…å®¹
            if response.text:
                final_response.text += response.text

            # æ›´æ–°ä½¿ç”¨æƒ…å†µ
            final_response.usage = response.usage
            final_response.stop_reason = response.stop_reason

            # å¦‚æœæœ‰æ€è€ƒå†…å®¹ï¼Œç´¯ç§¯
            if response.thinking:
                final_response.thinking = (final_response.thinking or "") + response.thinking

            # åˆ›å»º assistant æ¶ˆæ¯ï¼ˆåŒ…å«æ–‡æœ¬å’Œå·¥å…·è°ƒç”¨ï¼‰
            assistant_content = []
            if response.text:
                assistant_content.append(TextContent(text=response.text))
            if response.tool_calls:
                for tool_call in response.tool_calls:
                    assistant_content.append(
                        ToolUseContent(
                            id=tool_call.id,
                            name=tool_call.name,
                            input=tool_call.input
                        )
                    )

            if assistant_content:
                # å¦‚æœåªæœ‰ä¸€ä¸ª TextContentï¼Œå¯ä»¥ç›´æ¥ä¼ é€’ï¼›å¦åˆ™å¿…é¡»ä¼ é€’åˆ—è¡¨
                if len(assistant_content) == 1 and isinstance(assistant_content[0], TextContent):
                    content = assistant_content[0]
                else:
                    content = assistant_content

                await self.create_event(
                    Role.Assistant,
                    EventType.Message,
                    content
                )

            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¾ªç¯
            if not response.tool_calls:
                break

            # å¤„ç†å·¥å…·è°ƒç”¨
            final_response.tool_calls.extend(response.tool_calls)

            # æ‰§è¡Œå·¥å…·å¹¶æ”¶é›†ç»“æœ
            tool_results = []
            for tool_call in response.tool_calls:
                try:
                    result = self.agent.execute_tool(tool_call.name, tool_call.input)
                    tool_results.append(
                        ToolResultContent(
                            tool_use_id=tool_call.id,
                            content=self._format_tool_result(result)
                        )
                    )
                except Exception as e:
                    import traceback
                    error_msg = f"Tool execution error: {e!s}\n\nğŸ“‹ è¯¦ç»†å †æ ˆä¿¡æ¯ï¼š\n{traceback.format_exc()}"
                    tool_results.append(
                        ToolResultContent(
                            tool_use_id=tool_call.id,
                            content=error_msg
                        )
                    )

            # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
            await self.create_event(
                Role.User,
                EventType.ToolResult,
                tool_results
            )

            # ç´¯ç§¯å·¥å…·ç»“æœ
            if final_response.tool_results is None:
                final_response.tool_results = []
            final_response.tool_results.extend([r.content for r in tool_results])

            # å¦‚æœè¾¾åˆ° MaxTokens æˆ–å…¶ä»–åœæ­¢åŸå› ï¼Œç»“æŸå¾ªç¯
            if response.stop_reason in [StopReason.MaxTokens, StopReason.Refusal]:
                break

        return final_response

    async def invoke_with_console(
        self,
        role: str = "user",
        content: str = "",
        console_handler: ConsoleStreamHandler = None,
        max_rounds: int = 10
    ) -> CompleteResponse:
        """
        å¸¦æ§åˆ¶å°è¾“å‡ºçš„æ¥å£ï¼Œæ”¯æŒå¤šè½®å·¥å…·è°ƒç”¨

        Args:
            role: æ¶ˆæ¯è§’è‰²
            content: æ¶ˆæ¯å†…å®¹
            console_handler: æ§åˆ¶å°å¤„ç†å™¨
            max_rounds: æœ€å¤§è½®æ•°ï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰

        Returns:
            CompleteResponse: å®Œæ•´å“åº”
        """
        # åªåœ¨æœ‰å†…å®¹æ—¶æ·»åŠ åˆå§‹ç”¨æˆ·æ¶ˆæ¯ï¼ˆç¬¬ä¸€è½®ï¼‰
        if role and content:
            await self.create_event(Role(role), EventType.Message, TextContent(text=content))

        # å¦‚æœæ²¡æœ‰æä¾›æ§åˆ¶å°å¤„ç†å™¨ï¼Œåˆ›å»ºä¸€ä¸ª
        if console_handler is None:
            console_handler = ConsoleStreamHandler()

        # ç´¯ç§¯çš„å®Œæ•´å“åº”
        final_response = CompleteResponse(
            text="",
            tool_calls=[],
            stop_reason=None,
            usage=None,
            thinking=None,
            tool_results=[]
        )

        # å¾ªç¯å¤„ç†ï¼Œæœ€å¤š max_rounds è½®
        for round_num in range(max_rounds):
            # åŠ è½½ç³»ç»Ÿä¸Šä¸‹æ–‡
            system_prompt = await self._load_system_context()
            self.config.system_prompt = system_prompt

            # å‡†å¤‡ API æ¶ˆæ¯
            api_messages = [msg.transform_api() for msg in self.messages]

            # åˆ›å»ºæµ
            stream_params = {
                "model": self.config.model,
                "messages": api_messages,
                **self._build_request_params(),
                "timeout": self.config.timeout,
            }

            # æ·»åŠ  beta ç‰¹æ€§ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if self.config.beta and self.config.betas():
                stream_call = self.client.beta.messages.stream
                stream_params["betas"] = self.config.betas()
            else:
                stream_call = self.client.messages.stream

            # ä½¿ç”¨ StreamProcessor å¤„ç†æµï¼ŒåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°
            processor = StreamProcessor()

            async with stream_call(**stream_params) as stream:
                response = await processor.process_stream(
                    stream,
                    console_callback=console_handler.handle_stream_event
                )

            # ç´¯ç§¯å“åº”å†…å®¹
            if response.text:
                final_response.text += response.text

            # æ›´æ–°ä½¿ç”¨æƒ…å†µ
            final_response.usage = response.usage
            final_response.stop_reason = response.stop_reason

            # å¦‚æœæœ‰æ€è€ƒå†…å®¹ï¼Œç´¯ç§¯
            if response.thinking:
                final_response.thinking = (final_response.thinking or "") + response.thinking
                if round_num == 0:  # åªåœ¨ç¬¬ä¸€è½®æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹
                    print(f"\n\nğŸ’­ æ€è€ƒè¿‡ç¨‹:\n{response.thinking}")

            # åˆ›å»º assistant æ¶ˆæ¯ï¼ˆåŒ…å«æ–‡æœ¬å’Œå·¥å…·è°ƒç”¨ï¼‰
            assistant_content = []
            if response.text:
                assistant_content.append(TextContent(text=response.text))
            if response.tool_calls:
                for tool_call in response.tool_calls:
                    assistant_content.append(
                        ToolUseContent(
                            id=tool_call.id,
                            name=tool_call.name,
                            input=tool_call.input
                        )
                    )

            if assistant_content:
                # å¦‚æœåªæœ‰ä¸€ä¸ª TextContentï¼Œå¯ä»¥ç›´æ¥ä¼ é€’ï¼›å¦åˆ™å¿…é¡»ä¼ é€’åˆ—è¡¨
                if len(assistant_content) == 1 and isinstance(assistant_content[0], TextContent):
                    content = assistant_content[0]
                else:
                    content = assistant_content

                await self.create_event(
                    Role.Assistant,
                    EventType.Message,
                    content
                )

            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç»“æŸå¾ªç¯
            if not response.tool_calls:
                break

            # å¤„ç†å·¥å…·è°ƒç”¨
            final_response.tool_calls.extend(response.tool_calls)

            # æ‰§è¡Œå·¥å…·å¹¶æ”¶é›†ç»“æœ
            tool_results = []
            for tool_call in response.tool_calls:
                try:
                    print(f"\nâš™ï¸ æ‰§è¡Œå·¥å…·: {tool_call.name}")
                    result = self.agent.execute_tool(tool_call.name, tool_call.input)
                    tool_results.append(
                        ToolResultContent(
                            tool_use_id=tool_call.id,
                            content=self._format_tool_result(result)
                        )
                    )
                    print("âœ… å·¥å…·æ‰§è¡Œå®Œæˆ")

                    # æ˜¾ç¤ºå·¥å…·ç»“æœ
                    if isinstance(result, dict):
                        if result.get("stdout"):
                            print(f"\nğŸ“„ å·¥å…·ç»“æœ:\n{result['stdout']}")
                        elif result.get("output"):
                            print(f"\nğŸ“„ å·¥å…·ç»“æœ:\n{result['output']}")
                        elif result.get("stderr"):
                            print(f"\nâš ï¸ é”™è¯¯è¾“å‡º:\n{result['stderr']}")
                    elif isinstance(result, str) and result.strip():
                        print(f"\nğŸ“„ å·¥å…·ç»“æœ:\n{result}")

                except Exception as e:
                    import traceback
                    error_msg = f"Tool execution error: {e!s}\n\nğŸ“‹ è¯¦ç»†å †æ ˆä¿¡æ¯ï¼š\n{traceback.format_exc()}"
                    tool_results.append(
                        ToolResultContent(
                            tool_use_id=tool_call.id,
                            content=error_msg
                        )
                    )
                    print(f"âŒ å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")

            # å°†å·¥å…·ç»“æœæ·»åŠ åˆ°æ¶ˆæ¯å†å²
            await self.create_event(
                Role.User,
                EventType.ToolResult,
                tool_results
            )

            # ç´¯ç§¯å·¥å…·ç»“æœ
            if final_response.tool_results is None:
                final_response.tool_results = []
            final_response.tool_results.extend([r.content for r in tool_results])

            # å¦‚æœè¾¾åˆ° MaxTokens æˆ–å…¶ä»–åœæ­¢åŸå› ï¼Œç»“æŸå¾ªç¯
            if response.stop_reason in [StopReason.MaxTokens, StopReason.Refusal]:
                break

        return final_response

    async def create_event(
        self,
        role: Role,
        event_type: EventType,
        content: (
            TextContent | list[ThinkingContent | ToolUseContent | ToolResultContent | TextContent]
        ),
    ) -> Event:
        """Create and store an event"""
        event = Event(id=len(self.messages), role=role, type=event_type, content=content)
        self.messages.append(event)
        return event

    async def run(self, user_input: str) -> str:
        """Run a single turn (non-streaming) - compatible with existing interface"""
        # Collect all content from streaming
        full_response = ""

        async for event in self.invoke_stream(Role.User, user_input):
            if event.type == EventType.Message and event.role == Role.Assistant:
                if isinstance(event.content, TextContent):
                    full_response = event.content.text
                elif isinstance(event.content, list):
                    # Extract text from content list
                    for content in event.content:
                        if isinstance(content, TextContent):
                            full_response += content.text

        return full_response

    async def invoke_stream(
        self, role: Role | None = None, content: str | None = None
    ) -> AsyncIterator[Event]:
        """Stream chat response with full support for text, tool calls, and thoughts"""
        try:
            # Add user message if provided
            if role and content:
                yield await self.create_event(role, EventType.Message, TextContent(text=content))

            # Load system context
            system_prompt = await self._load_system_context()
            self.config.system_prompt = system_prompt

            # Prepare messages for API
            api_messages = [msg.transform_api() for msg in self.messages]

            # Create stream
            stream_params = {
                "model": self.config.model,
                "messages": api_messages,
                **self._build_request_params(),
                "timeout": self.config.timeout,
            }

            # Add beta features if enabled
            if self.config.beta and self.config.betas():
                stream_call = self.client.beta.messages.stream
                stream_params["betas"] = self.config.betas()
            else:
                stream_call = self.client.messages.stream

            async with stream_call(**stream_params) as stream:
                async for item in self._process_stream(stream):
                    yield item

        except Exception as e:
            # Create error event
            yield await self.create_event(
                Role.Assistant, EventType.Error, TextContent(text=f"Error: {e!s}")
            )

    async def _process_stream(
        self,
        stream: AsyncMessageStream,
    ) -> AsyncIterator[Event]:
        """Process the streaming response"""
        current_event: Event | None = None
        tool_uses: list[ToolUseContent] = []

        async for _chunk in stream:
            chunk: MessageStreamEvent = _chunk
            chunk_type = chunk.type

            if chunk_type == ChunkType.MessageStart:
                # Track usage
                usage = chunk.message.usage
                self.total_usage.merge(
                    Usage(
                        cache_creation_input_tokens=usage.cache_creation_input_tokens,
                        cache_read_input_tokens=usage.cache_read_input_tokens,
                        input_tokens=usage.input_tokens,
                        output_tokens=usage.output_tokens,
                    )
                )
                current_event = None
                continue

            if chunk_type == ChunkType.ContentBlockStart:
                content_block_type = chunk.content_block.type

                if content_block_type == ContentType.Text:
                    content_block: TextBlock = chunk.content_block
                    # åªåˆ›å»ºäº‹ä»¶ï¼Œä¸ç«‹å³è¾“å‡ºï¼Œç­‰å¾…å¢é‡å†…å®¹
                    current_event = await self.create_event(
                        role=Role.Assistant,
                        event_type=EventType.Message,
                        content=TextContent(text=""),  # åˆå§‹ä¸ºç©º
                    )

                elif content_block_type == ContentType.Thinking:
                    content_block: ThinkingBlock = chunk.content_block
                    # åªåˆ›å»ºäº‹ä»¶ï¼Œä¸ç«‹å³è¾“å‡º
                    current_event = await self.create_event(
                        role=Role.Assistant,
                        event_type=EventType.Thinking,
                        content=ThinkingContent(thinking=""),  # åˆå§‹ä¸ºç©º
                    )

                elif content_block_type == ContentType.ToolUse:
                    content_block: ToolUseBlock = chunk.content_block
                    current_event = await self.create_event(
                        role=Role.Assistant,
                        event_type=EventType.ToolUse,
                        content=[
                            ToolUseContent(
                                id=content_block.id,
                                name=content_block.name,
                                input=content_block.input or "",
                            )
                        ],
                    )
                    # ä¸è¦åœ¨è¿™é‡Œ yieldï¼Œç­‰åˆ° ContentBlockStop æ—¶å†è¾“å‡ºå®Œæ•´çš„å·¥å…·è°ƒç”¨

            if chunk_type == ChunkType.ContentBlockDelta:
                content_block_type = chunk.delta.type

                if content_block_type == ContentDeltaType.Text:
                    delta: TextDelta = chunk.delta
                    # åªè¾“å‡ºå¢é‡æ–‡æœ¬ï¼Œä¸ç´¯ç§¯
                    delta_event = await self.create_event(
                        role=Role.Assistant,
                        event_type=EventType.Message,
                        content=TextContent(text=delta.text)
                    )
                    yield delta_event
                    # ç´¯ç§¯åˆ°å½“å‰äº‹ä»¶ä¸­ï¼Œç”¨äºåç»­å¤„ç†
                    if current_event and isinstance(current_event.content, TextContent):
                        current_event.content.text += delta.text

                elif content_block_type == ContentDeltaType.Thinking:
                    delta: ThinkingDelta = chunk.delta
                    # åªè¾“å‡ºå¢é‡æ€è€ƒå†…å®¹
                    delta_event = await self.create_event(
                        role=Role.Assistant,
                        event_type=EventType.Thinking,
                        content=ThinkingContent(thinking=delta.thinking)
                    )
                    yield delta_event
                    # ç´¯ç§¯åˆ°å½“å‰äº‹ä»¶ä¸­
                    if current_event and isinstance(current_event.content, ThinkingContent):
                        current_event.content.thinking += delta.thinking

                elif content_block_type == ContentDeltaType.InputJson:
                    delta: InputJsonDelta = chunk.delta
                    if (
                        current_event
                        and isinstance(current_event.content, list)
                        and current_event.content
                    ):
                        # Get the last content block which should be ToolUseContent
                        last_content = current_event.content[-1]
                        if isinstance(last_content, ToolUseContent):
                            last_content.input = (
                                last_content.input + delta.partial_json
                                if isinstance(last_content.input, str)
                                else delta.partial_json
                            )
                            # ä¸è¦åœ¨è¿™é‡Œ yieldï¼Œç­‰åˆ°å·¥å…·è°ƒç”¨å®Œæˆæ—¶å†è¾“å‡º

            if (
                chunk_type == ChunkType.ContentBlockStop
                and current_event
                and current_event.type == EventType.ToolUse
                and isinstance(current_event.content, list)
                and current_event.content
            ):
                tool_use_content = current_event.content[-1]
                if isinstance(tool_use_content, ToolUseContent):
                    # Parse JSON input
                    if isinstance(tool_use_content.input, str):
                        try:
                            tool_use_content.input = json.loads(tool_use_content.input)
                        except json.JSONDecodeError:
                            self.agent.logger.logger.warning(
                                f"Invalid JSON in tool input: {tool_use_content.input}"
                            )
                            tool_use_content.input = {"INVALID_JSON": tool_use_content.input}
                    tool_uses.append(tool_use_content)
                yield current_event  # åªå¯¹å·¥å…·è°ƒç”¨è¾“å‡ºæœ€ç»ˆäº‹ä»¶
            # å¯¹äºæ–‡æœ¬å’Œæ€è€ƒå†…å®¹ï¼Œä¸åœ¨ ContentBlockStop æ—¶è¾“å‡ºï¼Œé¿å…é‡å¤

            if chunk_type == ChunkType.MessageDelta:
                stop_reason = chunk.delta.stop_reason
                usage = chunk.usage
                self.total_usage.merge(
                    Usage(
                        cache_creation_input_tokens=usage.cache_creation_input_tokens,
                        cache_read_input_tokens=usage.cache_read_input_tokens,
                        input_tokens=usage.input_tokens,
                        output_tokens=usage.output_tokens,
                    )
                )

                if stop_reason == StopReason.ToolUse:
                    yield current_event
                    # Handle tool calls
                    async for item in self._handle_tool_calls_stream(tool_uses):
                        yield item

                elif stop_reason in [StopReason.EndTurn, StopReason.MaxTokens]:
                    yield current_event

                elif stop_reason == StopReason.Refusal:
                    yield current_event
                    yield await self.create_event(
                        role=Role.Assistant,
                        event_type=EventType.Error,
                        content=TextContent(text="Model refused to generate response"),
                    )

            if chunk_type == ChunkType.MessageStop:
                yield current_event
                break

    async def _handle_tool_calls_stream(
        self, tool_uses: list[ToolUseContent]
    ) -> AsyncIterator[Event]:
        """Handle tool calls in streaming mode"""
        if not tool_uses:
            # è¿”å›ç©ºçš„å¼‚æ­¥ç”Ÿæˆå™¨è€Œä¸æ˜¯ None
            return
            yield  # è¿™è¡Œæ°¸è¿œä¸ä¼šæ‰§è¡Œï¼Œä½†è®©å‡½æ•°æˆä¸ºç”Ÿæˆå™¨

        # Create tool result event
        tool_results = []

        for tool_use in tool_uses:
            # Map new tool names to old ones for compatibility
            tool_name = tool_use.name
            tool_params = tool_use.input if isinstance(tool_use.input, dict) else {}

            # Parameter mapping for compatibility
            if tool_name == "read_file":
                mapped_params = {
                    "file_path": tool_params.get("path", ""),
                    "start_line": tool_params.get("start_line"),
                    "end_line": tool_params.get("end_line"),
                }
            elif tool_name == "write_file":
                mapped_params = {
                    "file_path": tool_params.get("path", ""),
                    "content": tool_params.get("content", ""),
                }
            elif tool_name == "list_directory":
                mapped_params = {"dir_path": tool_params.get("path", "")}
            elif tool_name == "execute_command":
                mapped_params = tool_params  # No mapping needed
            elif tool_name == "sync_context":
                mapped_params = {"new_context_content": tool_params.get("new_context_content", "")}
            else:
                mapped_params = tool_params

            # Execute tool
            try:
                result = self.agent.execute_tool(tool_name, mapped_params)
                result_content = self._format_tool_result(result)
                tool_results.append(
                    ToolResultContent(tool_use_id=tool_use.id, content=result_content)
                )
            except Exception as e:
                import traceback
                error_msg = f"Tool execution error: {e!s}\n\nğŸ“‹ è¯¦ç»†å †æ ˆä¿¡æ¯ï¼š\n{traceback.format_exc()}"
                tool_results.append(
                    ToolResultContent(
                        tool_use_id=tool_use.id, content=error_msg
                    )
                )

        # Create and yield tool result event
        current_event = await self.create_event(
            role=Role.User, event_type=EventType.ToolResult, content=tool_results
        )
        yield current_event

        # Continue conversation
        async for item in self.invoke_stream():
            yield item

    def _format_tool_result(self, result: Any) -> str:
        """Format tool result for display"""
        if isinstance(result, dict):
            if "content" in result:
                return str(result["content"])
            elif "stdout" in result:
                # Command execution result
                output = f"Exit code: {result.get('returncode', 'N/A')}\n"
                if result.get("stdout"):
                    output += f"Output:\n{result['stdout']}"
                if result.get("stderr"):
                    output += f"\nError:\n{result['stderr']}"
                return output
            else:
                return json.dumps(result, ensure_ascii=False, indent=2)
        else:
            return str(result)
